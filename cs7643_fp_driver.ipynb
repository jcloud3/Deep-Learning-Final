{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cs7643-fp-driver.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjKEorK_tbQd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuwZJmuGvld9"
      },
      "source": [
        "# Mount your drive folder\n",
        "\n",
        "# TODO: \n",
        "# Make sure to replace drive_path to your google drive folder\n",
        "# Remember to upload the zipped resized data to the data folder\n",
        "# Create folder data/annotations/\n",
        "# Remember to upload the captions_train2014.json to data/annotations folder\n",
        "\n",
        "drive_path = \"/content/drive/MyDrive/Colab\\ Notebooks/cs7643-fp\"\n",
        "\n",
        "!ls {drive_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg9qHJ6ZvoAi"
      },
      "source": [
        "# Copy files from Google Drive to Google Collab so less network usage\n",
        "# This will take a while\n",
        "\n",
        "work_dir = \"/home/workdir/\"\n",
        "\n",
        "!mkdir -p {work_dir}\n",
        "%cd {work_dir}\n",
        "!cp -r {drive_path} {work_dir}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FldvrOGg02tY"
      },
      "source": [
        "# Move to new workdir\n",
        "\n",
        "work_dir = \"/home/workdir/cs7643-fp/\"\n",
        "%cd {work_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jtgoxQ3vn8b"
      },
      "source": [
        "# Unzip the resized validation and training data\n",
        "\n",
        "data_path = f\"{work_dir}image_captioning/data/\"\n",
        "\n",
        "%cd {data_path}\n",
        "!unzip resized2014.zip\n",
        "!unzip resized_val2014.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qihdX9TAvl19"
      },
      "source": [
        "# Install python requirements\n",
        "\n",
        "%cd {work_dir}\n",
        "!cat requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!python -m nltk.downloader punkt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8U8fyqj2nm7"
      },
      "source": [
        "# Train\n",
        "\n",
        "!python -m image_captioning.train \\\n",
        "    --save_step 1000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8j1jTT9SoE0"
      },
      "source": [
        "!ls image_captioning/models/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiuQxm0d4Oqv"
      },
      "source": [
        "# Once the training is done, Google Collab will release resource if you're not active on the\n",
        "# notebook. So you should queue this cell after the train cell to save the models to your\n",
        "# persistant storage on Google Drive.\n",
        "# For the file names, the first number is the epoch number and the second number is the iteration\n",
        "# number. By default, train.py will save a checkpoint file for each epoch every 1000 loops.\n",
        "\n",
        "import yaml\n",
        "\n",
        "with open(\"image_captioning/configs/default.yaml\") as fp:\n",
        "  dd = yaml.safe_load(fp)\n",
        "\n",
        "encoder_model = dd[\"Train\"][\"encoder_model\"]\n",
        "epoch_count = 5\n",
        "step_count = 3000\n",
        "\n",
        "!cp image_captioning/models/encoder-{encoder_model}-{epoch_count}-{step_count}.ckpt {drive_path}/image_captioning/models/\n",
        "!cp image_captioning/models/decoder-{epoch_count}-{step_count}.ckpt {drive_path}/image_captioning/models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPptxNboXz81"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}